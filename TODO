Taylor_Expansion branch:
- (DONE) Add a MatrixMatrixFunc type of derivative for elementwise product.
- (DONE) FIXME: even though the row and colume number do not meet the 
  the requirement, e.g trace(mat(3*4)) the symbolic calculator also 
  has an output. ( -DCMAKE_BUILD_TYPE=Debug )
- Exception handlings.(violation of linear algebra rules. Invalid input etc).
- (DONE)Operator * for ScalarMatrixFunc class. 
  e.g. (f*g' + f'g) SalarMatrixFunc * MatrixMatrixFunc.
- Operator / for ScalarMatrixFunc class? There is no "/" between SMF and MMF. 
//  08/14/2014
- Add samples showing how to use the program. (1 Taylor, 1 Derivative, 1
  Elemental.)
- Add "int" * SMF in calculator 
- Add more details about calculator in README.md  and mention that elemental
  does not run on Windows. If you do not need to use elemental you only need to
  install boost and cmake and a git which can download the source from github.

From Peder and Anju:
--------------------
- Common subexpression elimination

- MatrixAdaptor needs to be used to create a new matrix. Currently we just say
  "new MT", which is wrong. This also means that currently we have to resize 
  any matrix before performing operations --- take a look at 
  ElementalMatrixAdaptor::add() as an example. I have added a new function 
  in MatrixAdaptor (func number 0). ****

- Constructor of MMFunc takes in MatrixType by value. Then it creates a new 
  copy constructed MatrixType from this copy. Ideally, we should not even 
  have one copy, let alone two. Furthermore, we are assuming the presence 
  of a copy constructor. We have to go through MatrixAdaptor instead ****

- (DONE)The order of the MMF arguments has to be the same as that of the matrices.
  Otherwise, people get really confused. For example:

template <class MT, class ST>
void negationOp( boost::shared_ptr<MT> result,
      boost::shared_ptr<MT> current,
      boost::shared_ptr<MT> left,
      boost::shared_ptr<MT> right,
      boost::shared_ptr<MatrixMatrixFunc<MT, ST> >  currentMMF ,
      boost::shared_ptr<MatrixMatrixFunc<MT, ST> >  rightMMF ,
      boost::shared_ptr<MatrixMatrixFunc<MT, ST> >  leftMMF ,
      boost::shared_ptr<MatrixMatrixFunc<MT, ST> >  resultMMF ,
      const MatrixMatrixFunc<MT,ST>* node,
      int& transposeFlag,
      bool& identityCurrentFlag,
      bool& zeroResultFlag) {

CHANGE TO:

template <class MT, class ST>
void negationOp( boost::shared_ptr<MT> result,
      boost::shared_ptr<MT> current,
      boost::shared_ptr<MT> currentLeft,
      boost::shared_ptr<MT> currentRight,
      boost::shared_ptr<MatrixMatrixFunc<MT, ST> >  resultMMF,
      boost::shared_ptr<MatrixMatrixFunc<MT, ST> >  currentMMF,
      boost::shared_ptr<MatrixMatrixFunc<MT, ST> >  currentLeftMMF,
      boost::shared_ptr<MatrixMatrixFunc<MT, ST> >  currentRightMMF,
      const MatrixMatrixFunc<MT,ST>* node,
      int& transposeFlag,
      bool& identityCurrentFlag,
      bool& zeroResultFlag) {

- In binOpSet(), why do you need to deepCopy() the right and left children?
  Isn't it sufficient to simply point to them? (****)

- All pointers should be boost::shared_ptr<>. There are some that are not, 
  which is dangerous. binOpSet() should accept boost::shared_ptr<> to it's 
  children. Remember to change the calling sites of boost::shared_ptr<> 
  in MatrixMatrixFuncHelper() --- this is +, -, *, .* (****)

- Same problem as above with unaryOpSet(). Fix it.

- Lots of places where we are creating extra copies of the matrices. We need 
  to avoid this. Matrices might be huge and copying them unnecessarily is 
  not an option.

- In constructing the derivateFuncVal, in varOp(), we do a deepCopy(), why?
  MatrixMatrixFuncHelper:162   
      "(*resultMMF).deepCopy((*resultMMF) + (*currentMMF));"

  When leftChild and rightChild are changed to become boost::shared_ptr<> to 
  MatrixMatrixFunc, we will not need a deepCopy. None of the functions change
  the MatrixMatrixFunc. So, no need to create new MatrixMatrixFuncs everytime.
  Ultimately, we need to be able to remove shallowCopy() and deepCopy(). The
  compiler provided default "operator=" should be sufficient.

- In the calculator, functions such as trace(trace(fX)*fX) are not computed 
  properly. These things are considered as trace(trace(X)*constant) and 
  some erroneous result is output.

- Figure out how derivatives of things such as trace(trace(X)*X) can be 
  computed. The derivative of this to me seems to be of the wrong dimensions.
  If you apply the chain rule, you get mis-matched dimensions, but in the 
  answers, you get something with elementWise product in it. How?

- Create presentations that are accurate with respect to what happens within 
  the library. This can be an animation or PPT or a beamer presentation. 

- TODOs from the other day at IBM were:
    -- Common sub-expression elimination
    -- Support for Eigen matrix package
    -- Avoid duplicating MMFunc nodes.

- Anju will send an example slide out on documenting how a function such as 
  trace((A+X)*X) is evaluated inside AMD. Suyang will add similar examples for
  other ScalarMatrix functions and also for functions such as trace(trace(X)*X)

Discussion with Suyang (August 19th):
-------------------------------------
The files that implement the core functionality is in "AMD" subdirectory.

AMD.hpp: Global header file that basically includes all other files.

MatrixAdaptor.hpp: This is an abstraction which all of AMD uses to abstract 
                   away from hardcoding specific matrix types. Currently we
                   have: Elemental::Matrix and SymbolicMatrixMatlab. But we 
                   really need: Elemental::DistMatrix<> and all of Eigen to 
                   be supported.
ElementalMatrixAdaptor.hpp: Specialization
SymbolicMatrixAdaptor.hpp:  Specialization

SymbolicMatrixMatlab.hpp: This is a basically an implementation of a matrix 
                          that provides "symbolic" operations. For example,
                          the matrix "A"*"B" gives the matrix "A*B". This is 
                          used to generate pretty answers.
SymbolicMatrixMatlabHelper.hpp: Provides all the matrix operations that we are 
                                interested in as free functions. The functions
                                include trace, logdet, inv, transpose, +, -, 
                                *, /, etc. These are normal functions. trace(A)
                                returns the value of the trace of a matrix A.
                                Nothing special.
                  
SymbolicScalarMatlab.hpp: This is a the scalar counter-part of 
                          SymbolicMatrixMatlab.hpp. Probably can be eliminated.
SymbolicScalarMatlabHelper.hpp: Provides all the scalar operations that we are 
                                interested in as free functions. The functions
                                include trace, logdet, inv, transpose, +, -, 
                                *, /, etc.

MatrixMatrixFunc.hpp: AMD operates by constructing operations trees. For 
                      example, A*B is a 3 node tree with A and B as the leaves
                      and * (actually A*B) as their parent. MatrixMatrixFunc
                      represents all functions that have a matrix as both their
                      domain and range. Every node in the tree has to be a 
                      MatrixMatrixFunc, which means that the leaves have to 
                      be identity MatrixMatrixFunc that take in a matrix and 
                      return the same matrix. There are two types of these 
                      identity MatrixMatrixFunc --- varibles and constants.

MatrixMatrixFuncHelper.hpp:

ScalarMatrixFunc.hpp:

